{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ac3074",
   "metadata": {},
   "source": [
    "### Parsing the 'PragTic' fatigue database\n",
    "First of all, let's import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39573a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e04367",
   "metadata": {},
   "source": [
    "If one looks at the 'Pragtic' dataset, one may see that it contains complicated tables with columns and rows that contain sub-columns and sub-rows (see, for example, here: https://www.pragtic.com/curve.php?action=view&type=curve&tgr_id=19&cur_id=127). There are some solutions on the internet on how to work with it. Below, there is one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78671d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code snippet was taken from: https://stackoverflow.com/questions/28763891/what-should-i-do-when-tr-has-rowspan\n",
    "\n",
    "def pre_process_table(table):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        1. table - a bs4 element that contains the desired table: ie <table> ... </table>\n",
    "    OUTPUT:\n",
    "        a tuple of: \n",
    "            1. rows - a list of table rows ie: list of <tr>...</tr> elements\n",
    "            2. num_rows - number of rows in the table\n",
    "            3. num_cols - number of columns in the table\n",
    "    Options:\n",
    "        include_td_head_count - whether to use only th or th and td to count number of columns (default: False)\n",
    "    \"\"\"\n",
    "    rows = [x for x in table.find_all('tr')]\n",
    "\n",
    "    num_rows = len(rows)\n",
    "\n",
    "    # get an initial column count. Most often, this will be accurate\n",
    "    num_cols = max([len(x.find_all(['th','td'])) for x in rows])\n",
    "\n",
    "    # sometimes, the tables also contain multi-colspan headers. This accounts for that:\n",
    "    header_rows_set = [x.find_all(['th', 'td']) for x in rows if len(x.find_all(['th', 'td']))>num_cols/2]\n",
    "\n",
    "    num_cols_set = []\n",
    "\n",
    "    for header_rows in header_rows_set:\n",
    "        num_cols = 0\n",
    "        for cell in header_rows:\n",
    "            row_span, col_span = get_spans(cell)\n",
    "            num_cols+=len([cell.getText()]*col_span)\n",
    "\n",
    "        num_cols_set.append(num_cols)\n",
    "\n",
    "    num_cols = max(num_cols_set)\n",
    "\n",
    "    return (rows, num_rows, num_cols)\n",
    "\n",
    "\n",
    "def get_spans(cell):\n",
    "        \"\"\"\n",
    "        INPUT:\n",
    "            1. cell - a <td>...</td> or <th>...</th> element that contains a table cell entry\n",
    "        OUTPUT:\n",
    "            1. a tuple with the cell's row and col spans\n",
    "        \"\"\"\n",
    "        if cell.has_attr('rowspan'):\n",
    "            rep_row = int(cell.attrs['rowspan'])\n",
    "        else: # ~cell.has_attr('rowspan'):\n",
    "            rep_row = 1\n",
    "        if cell.has_attr('colspan'):\n",
    "            rep_col = int(cell.attrs['colspan'])\n",
    "        else: # ~cell.has_attr('colspan'):\n",
    "            rep_col = 1 \n",
    "\n",
    "        return (rep_row, rep_col)\n",
    "\n",
    "def process_rows(rows, num_rows, num_cols):\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        1. rows - a list of table rows ie <tr>...</tr> elements\n",
    "    OUTPUT:\n",
    "        1. data - a Pandas dataframe with the html data in it\n",
    "    \"\"\"\n",
    "    data = pd.DataFrame(np.ones((num_rows, num_cols))*np.nan)\n",
    "    for i, row in enumerate(rows):\n",
    "        try:\n",
    "            col_stat = data.iloc[i,:][data.iloc[i,:].isnull()].index[0]\n",
    "        except IndexError:\n",
    "            print(i, row)\n",
    "\n",
    "        for j, cell in enumerate(row.find_all(['td', 'th'])):\n",
    "            rep_row, rep_col = get_spans(cell)\n",
    "\n",
    "            #print(\"cols {0} to {1} with rep_col={2}\".format(col_stat, col_stat+rep_col, rep_col))\n",
    "            #print(\"\\trows {0} to {1} with rep_row={2}\".format(i, i+rep_row, rep_row))\n",
    "\n",
    "            #find first non-na col and fill that one\n",
    "            while any(data.iloc[i,col_stat:col_stat+rep_col].notnull()):\n",
    "                col_stat+=1\n",
    "\n",
    "            data.iloc[i:i+rep_row,col_stat:col_stat+rep_col] = cell.getText()\n",
    "            if col_stat<data.shape[1]-1:\n",
    "                col_stat+=rep_col\n",
    "\n",
    "    return data\n",
    "\n",
    "def main(table):\n",
    "    rows, num_rows, num_cols = pre_process_table(table)\n",
    "    df = process_rows(rows, num_rows, num_cols)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459d4cc1",
   "metadata": {},
   "source": [
    "Then, we need to go through all the pages and collect the information from them.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331762ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 2 cases: 4 or 3 tables and 2 tables on a webpage of a SUBgroup (BaB01, BaB02,..., Bai01, Bai02, ...). \n",
    "# So, let's make 2 DataFrame for both cases\n",
    "df_test_4 = pd.DataFrame({'pragtic_test_group':[],'material':[],'Research_ref':[],'Pragtic_ref_id':[]}) #\n",
    "df_test_2 = pd.DataFrame({'pragtic_test_group':[],'material':[],'Research_ref':[],'Pragtic_ref_id':[]}) #\n",
    "\n",
    "page_0 = requests.get('http://www.pragtic.com/experiments.php') # Getting page HTML\n",
    "soup_0 = BeautifulSoup(page_0.content, 'html.parser') # Parsing content by BeautifulSoup\n",
    "links_0 = soup_0.select(\"tr td select.mode option\") # Selecting all the anchors with fatigue tests\n",
    "\n",
    "for link in links_0[2:59]:   \n",
    "    href = 'https://www.pragtic.com/experiments.php?action=view&type=group&tgr_id='+link['value'] # refs for each group (BaB,...)\n",
    "    page = requests.get(href) # Getting page HTML for each group (BaB, Bai, ...)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser') # Parsing content by BeautifulSoup for each group (BaB, Bai, ...)\n",
    "    # Reference to research\n",
    "    r_index = [i+1 for i in range(len(soup.select(\"tr td \"))) if soup.select(\"tr td \")[i].contents[0] == 'Referenced in:'][0]\n",
    "    Ref = soup.select(\"tr td \")[r_index].contents[1]\n",
    "    pragtic_ref_id = soup.select(\"tr td \")[r_index].select(\"b\")[0].contents[0].split('\\n:')[0] # reference ID\n",
    "    \n",
    "    # Selecting all the anchors with material information\n",
    "    material_link = soup.find_all('a', attrs={'href': lambda e: e.startswith(\n",
    "        'https://www.pragtic.com/vmat.php?post=') if e else False})\n",
    "    material_href = material_link[0]['href'] # ref with material information (Ck 35, ...)\n",
    "    material_page = requests.get(material_href) # Getting page HTML for each material (Ck 35, ...)\n",
    "    material_soup = BeautifulSoup(material_page.content, 'html.parser') # Parsing content by BeautifulSoup for each material\n",
    "    material_tables = material_soup.select('table') # All the tables on the page \n",
    "    \n",
    "    # General material information (marks, standard, group)\n",
    "    rows, num_rows, num_cols = pre_process_table(material_tables[2])\n",
    "    mater_mark = process_rows(rows, num_rows, num_cols).iloc[0,1] + '/'+ process_rows(rows, num_rows, num_cols).iloc[1,1]\n",
    "    mater_standard = process_rows(rows, num_rows, num_cols).iloc[2,1]\n",
    "    mater_group = process_rows(rows, num_rows, num_cols).iloc[3,1]\n",
    "    temp_tab_mater = pd.DataFrame({'mater_mark_alt':[mater_mark],'mater_standard':[mater_standard],'mater_group':[mater_group]})\n",
    "    \n",
    "    # Chemical composition table\n",
    "    rows, num_rows, num_cols = pre_process_table(material_tables[3])\n",
    "    balance = process_rows(rows, num_rows, num_cols).iloc[-1,-1] # Information about additional chemical components\n",
    "    balance_tab = pd.DataFrame({'balance':[balance]})\n",
    "    # Chemical composition\n",
    "    rows, num_rows, num_cols = pre_process_table(material_tables[-2])\n",
    "    df_material_ch_com = process_rows(rows, num_rows, num_cols)\n",
    "    if len(df_material_ch_com) > 3:\n",
    "        df_material_ch_com = df_material_ch_com.iloc[:,::-1].iloc[2:-1,-4:].T.iloc[:3]\n",
    "        df_material_ch_com.columns = df_material_ch_com.iloc[0].str.cat(df_material_ch_com.iloc[1]).copy()\n",
    "        df_material_ch_com = df_material_ch_com.iloc[[2]].reset_index(drop=True)\n",
    "        temp_tab_mater = pd.concat([temp_tab_mater,df_material_ch_com,balance_tab], axis=1) # Concatenation of tables\n",
    "    else: \n",
    "        temp_tab_mater = pd.concat([temp_tab_mater,balance_tab], axis=1) # Concatenation of tables\n",
    "    \n",
    "    # Tables with treatment information\n",
    "    rows, num_rows, num_cols = pre_process_table(material_tables[4])\n",
    "    df_material_tr = process_rows(rows, num_rows, num_cols).T.copy()\n",
    "    df_material_tr.columns = ['mater_ref', 'mater_comment', 'mater_treatment']\n",
    "    df_material_tr = df_material_tr.iloc[[1]].reset_index(drop=True)\n",
    "    temp_tab_mater = pd.concat([temp_tab_mater,df_material_tr], axis=1) # Concatenation of tables\n",
    "    \n",
    "    # Mechanical properties tables\n",
    "    for i in range(len(material_tables[5:-2])):\n",
    "        rows, num_rows, num_cols = pre_process_table(material_tables[i+5])\n",
    "        df_mat_prop = process_rows(rows, num_rows, num_cols)\n",
    "        if len(df_mat_prop) > 3:\n",
    "            tab_name = df_mat_prop.iloc[0,0]\n",
    "            df_mat_prop = df_mat_prop.iloc[:,::-1].iloc[2:-1,-4:].T.iloc[:3]\n",
    "            df_mat_prop.columns = tab_name + ' ' + df_mat_prop.iloc[0].str.cat(df_mat_prop.iloc[1])\n",
    "            df_mat_prop = df_mat_prop.iloc[[2]].reset_index(drop=True)\n",
    "            temp_tab_mater = pd.concat([temp_tab_mater,df_mat_prop], axis=1)\n",
    "    \n",
    "    # Selecting all the anchors with fatigue SUBgroup (BaB01, BaB02,..., Bai01, Bai02, ...)\n",
    "    s_links = soup.find_all('a', attrs={'href': lambda e: e.startswith(\n",
    "                'https://www.pragtic.com/curve.php?action=view&type=curve&tgr_id') if e else False})    \n",
    "    \n",
    "    for i in range(len(s_links)):\n",
    "        s_href = 'https://www.pragtic.com/curve.php?action=view&type=curve&tgr_id=' + link['value'] +\\\n",
    "                    '&cur_id=' + s_links[i]['href'].split('cur_id=')[-1] # refs for each SUBgroup (BaB01,..., Bai01, ...)\n",
    "        s_page = requests.get(s_href) # Getting page HTML for each SUBgroup (BaB01, BaB02,..., Bai01, Bai02, ...)\n",
    "        s_soup = BeautifulSoup(s_page.content, 'html.parser') # Parsing content by BeautifulSoup for each SUBgroup\n",
    "        s_tables = s_soup.select('table') # All the tables for each SUBgroup (BaB01, BaB02,..., Bai01, Bai02, ...)\n",
    "        \n",
    "        # Creating the complex table with specimen information\n",
    "        rows_2, num_rows_2, num_cols_2 = pre_process_table(s_tables[-1])\n",
    "        test_tab_2 = process_rows(rows_2, num_rows_2, num_cols_2)\n",
    "        spec_type = test_tab_2.loc[0,0] # Specimen type\n",
    "        spec_comment = test_tab_2.iloc[-1,1] # Commentary about specimens\n",
    "        # Table with information about specimen geometry\n",
    "        temp_tab_2 = pd.DataFrame({'Specimen_type':[],'Specimen_comment':[]})\n",
    "        test_tab_21 = test_tab_2.iloc[1:-1,:2].set_index(0).T.reset_index(drop=True)\n",
    "        temp_tab_2 = pd.concat([temp_tab_2,test_tab_21,temp_tab_mater], axis=1)\n",
    "        temp_tab_2.fillna({'Specimen_type':spec_type,'Specimen_comment':spec_comment}, inplace=True)\n",
    "        \n",
    "        if len(s_tables[1:]) == 4 or len(s_tables[1:]) == 3:\n",
    "            # Creating the complex table\n",
    "            rows, num_rows, num_cols = pre_process_table(s_tables[2])\n",
    "            test_tab_3_4 = process_rows(rows, num_rows, num_cols)\n",
    "            # Cleaning the table\n",
    "            test_tab_3_4.columns = test_tab_3_4.loc[0].str.cat(test_tab_3_4.loc[1]).copy() # Renaming columns\n",
    "            test_tab_3_4.drop([0, 1], inplace=True) # Dropping the first 2 rows\n",
    "            test_tab_3_4[temp_tab_2.columns] = temp_tab_2.iloc[0]\n",
    "            df_test_4 = pd.concat([df_test_4,test_tab_3_4])\n",
    "            \n",
    "        elif len(s_tables[1:]) == 2: \n",
    "            # Creating the complex table\n",
    "            rows, num_rows, num_cols = pre_process_table(s_tables[1])\n",
    "            test_tab = process_rows(rows, num_rows, num_cols)\n",
    "            # Number of cycles at fatigue limit\n",
    "            try: fat_life = float(test_tab[test_tab[0] == 'Number of cycles at fat. lim.:'].values[0, 1])\n",
    "            except: fat_life = 1 # if there is no fatigue life\n",
    "            test_tab1 = test_tab[test_tab[0] == 'Load channels:'] # It contains only information about loading\n",
    "            try: fat_lim = float(test_tab[test_tab[0] == 'Fatigue limit:'].values[0, 1]) # Fatigue limit\n",
    "            except: fat_lim = 0 # if there is no fatigue limit\n",
    "            Mark = test_tab[test_tab[0] == 'Curve mark:'].values[0, 1] # Name of SUBgroup (Ber01,..., TAK01, ...)\n",
    "            temp_tab = pd.DataFrame({'Mark':[],'N':[], 'Completed':[]}) \n",
    "            temp_tab = pd.concat([temp_tab_2,temp_tab], axis=1).reset_index(drop=True)\n",
    "            for i in range(2,len(test_tab1.index),3):\n",
    "                col1 = test_tab1.iloc[i-1][test_tab1.iloc[i-1] == '\\xa0'] # Columns without relevant information\n",
    "                test_tab11 = test_tab1.iloc[i-2:i+1].drop(columns=col1.index) # Dropping those columns\n",
    "                test_tab11.columns = test_tab11.iloc[0]\\\n",
    "                        .str.cat(test_tab11.iloc[1]).copy() # Renaming columns by combining info from the 1st two rows\n",
    "                test_tab11.drop(test_tab11.index[:2], inplace=True) # Dropping the 1st two rows\n",
    "                # Multiplyer of the fatigue limit\n",
    "                try: mult = float(test_tab11.iloc[0,:][test_tab11.iloc[0,:].str.contains('x')].values[0].split('x')[1])\n",
    "                except: mult = 0\n",
    "                # Multiplication of the fatigue limit and multiplier\n",
    "                test_tab11.iloc[0,:][test_tab11.iloc[0,:].str.contains('x')] = mult*fat_lim\n",
    "                test_tab11.drop(columns=test_tab11.columns[:2], inplace=True) # Dropping columns without relevant information\n",
    "                test_tab11.reset_index(drop=True, inplace=True)\n",
    "                temp_tab = pd.concat([temp_tab,test_tab11], axis=1) # Concatenation of tables\n",
    "                # Filling NaN values in columns\n",
    "                temp_tab.fillna({'N':fat_life,'Completed':'Fatigue limit','Mark':Mark}, inplace=True)\n",
    "            df_test_2 = pd.concat([df_test_2,temp_tab])\n",
    "    \n",
    "    # Filling NaN values in columns\n",
    "    df_test_4.fillna({'pragtic_test_group':link.contents[0],'material':material_link[0].contents[0],\n",
    "                      'Research_ref':Ref,'Pragtic_ref_id':pragtic_ref_id}, inplace=True)\n",
    "    df_test_2.fillna({'pragtic_test_group':link.contents[0],'material':material_link[0].contents[0],\n",
    "                      'Research_ref':Ref,'Pragtic_ref_id':pragtic_ref_id}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f3e2fb",
   "metadata": {},
   "source": [
    "The column names look a bit messy, so let's correct them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76ed97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "df_test_4.rename(columns={\"MarkMark\": \"Mark\", \"NN\": \"N\", 'CompletedCompleted':'Completed',\n",
    "                         'Static data Ultimate tensile strengthMPa': 'Ultim_tens_str_MPa',\n",
    "                         'Static data Ultimate shear strengthMPa': 'Ultim_shear_str_MPa',\n",
    "                         'Static data Tensile yield stressMPa': 'Tens_yield_str_MPa',\n",
    "                         'Static data Shear yield stressMPa': 'Shear_yield_str_MPa',\n",
    "                         'Fully reversed push-pull Diameter of specimen at active cross-sectionmm':'Ful_rev_T_C_Spec_Diam_mm',\n",
    "                         'Fully reversed push-pull Fatigue limitMPa': 'Ful_rev_T_C_Fat_lim_MPa',\n",
    "                         'Fully reversed push-pull Exponent of S-N curve-': 'Ful_rev_T_C_Exp_SN_curv',\n",
    "                         'Fully reversed push-pull Number of cycles at fatigue limit-': 'Ful_rev_T_C_N_for_fat_lim',\n",
    "                         'Repeated tension Fatigue limitMPa': 'Repeat_T_Fat_lim_MPa',\n",
    "                         'Repeated tension Exponent of S-N curve-': 'Repeat_T_Exp_SN_curv',\n",
    "                         'Repeated tension Number of cycles at fatigue limit-': 'Repeat_T_N_for_fat_lim',\n",
    "                         'Fully reversed torsion Diameter of specimen at active cross-sectionmm': 'Ful_rev_Tor_Spec_Diam_mm',\n",
    "                         'Fully reversed torsion Fatigue limitMPa': 'Ful_rev_Tor_Fat_lim_MPa',\n",
    "                         'Fully reversed torsion Exponent of S-N curve-': 'Ful_rev_Tor_Exp_SN_curv',\n",
    "                         'Fully reversed torsion Number of cycles at fatigue limit-': 'Ful_rev_Tor_N_for_fat_lim',\n",
    "                         'Repeated torsion Fatigue limitMPa': 'Repeat_Tor_Fat_lim_MPa',\n",
    "                         'Repeated torsion Exponent of S-N curve-': 'Repeat_Tor_Exp_SN_curv',\n",
    "                         'Repeated torsion Number of cycles at fatigue limit-': 'Repeat_Tor_N_for_fat_lim',\n",
    "                         'Static data Reduction of area at fracture%': 'Reduction_area_frac_%',\n",
    "                         'Static data Ambient temperaturedegC': 'Stat_temper_C',\n",
    "                         'Static data Tensile elasticity modulusMPa': 'Tens_elast_modul_MPa',\n",
    "                         'Static data Elongation at fracture%': 'Stat_Elong_frac_%',\n",
    "                         'To - harmonic, constant amplitudeA': 't_a_MPa',\n",
    "                         'To - harmonic, constant amplitudeF': 'Freq_t_Hz',\n",
    "                         'To - harmonic, constant amplitudePS': 'PS_t_deg',\n",
    "                         'TP - harmonic, constant amplitudeA': 'tan_a(pres)_MPa)',\n",
    "                         'TP - harmonic, constant amplitudeM': 'tan_m(pres)_MPa)',\n",
    "                         'TP - harmonic, constant amplitudeF': 'Freq_tan_Hz',\n",
    "                         'TP - harmonic, constant amplitudePS': 'PS_tan_deg',\n",
    "                         'Carbon content%': 'Carbon_%', 'Silicon content%': 'Silicon_%', \n",
    "                         'Manganese content%': 'Manganese_%', 'Phosphorus content%': 'Phosphorus_%', \n",
    "                         'Sulphur content%': 'Sulphur_%',}, inplace=True)\n",
    "\n",
    "df_test_2.rename(columns={'Static data Ultimate tensile strengthMPa': 'Ultim_tens_str_MPa',\n",
    "                         'Static data Ultimate shear strengthMPa': 'Ultim_shear_str_MPa',\n",
    "                         'Static data Tensile yield stressMPa': 'Tens_yield_str_MPa',\n",
    "                         'Static data Shear yield stressMPa': 'Shear_yield_str_MPa',\n",
    "                         'Fully reversed push-pull Diameter of specimen at active cross-sectionmm':'Ful_rev_T_C_Spec_Diam_mm',\n",
    "                         'Fully reversed push-pull Fatigue limitMPa': 'Ful_rev_T_C_Fat_lim_MPa',\n",
    "                         'Fully reversed push-pull Exponent of S-N curve-': 'Ful_rev_T_C_Exp_SN_curv',\n",
    "                         'Fully reversed push-pull Number of cycles at fatigue limit-': 'Ful_rev_T_C_N_for_fat_lim',\n",
    "                         'Repeated tension Fatigue limitMPa': 'Repeat_T_Fat_lim_MPa',\n",
    "                         'Repeated tension Exponent of S-N curve-': 'Repeat_T_Exp_SN_curv',\n",
    "                         'Repeated tension Number of cycles at fatigue limit-': 'Repeat_T_N_for_fat_lim',\n",
    "                         'Fully reversed torsion Diameter of specimen at active cross-sectionmm': 'Ful_rev_Tor_Spec_Diam_mm',\n",
    "                         'Fully reversed torsion Fatigue limitMPa': 'Ful_rev_Tor_Fat_lim_MPa',\n",
    "                         'Fully reversed torsion Exponent of S-N curve-': 'Ful_rev_Tor_Exp_SN_curv',\n",
    "                         'Fully reversed torsion Number of cycles at fatigue limit-': 'Ful_rev_Tor_N_for_fat_lim',\n",
    "                         'Repeated torsion Fatigue limitMPa': 'Repeat_Tor_Fat_lim_MPa',\n",
    "                         'Repeated torsion Exponent of S-N curve-': 'Repeat_Tor_Exp_SN_curv',\n",
    "                         'Repeated torsion Number of cycles at fatigue limit-': 'Repeat_Tor_N_for_fat_lim',\n",
    "                         'Static data Reduction of area at fracture%': 'Reduction_area_frac_%',\n",
    "                         'Static data Ambient temperaturedegC': 'Stat_temper_C',\n",
    "                         'Static data Tensile elasticity modulusMPa': 'Tens_elast_modul_MPa',\n",
    "                         'Static data Elongation at fracture%': 'Stat_Elong_frac_%',\n",
    "                         'Static data Hardness (acc. to Rockwell)-': 'Stat_Hardness_Rockwell',\n",
    "                         'Static data Hardness (acc. to Brinell)-': 'Stat_Hardness_Brinell', \n",
    "                         'Static data Hardness (acc. to Vickers)-': 'Stat_Hardness_Vickers',\n",
    "                         'Static data Coefficient of static strengthMPa': 'Coef_stat_str_MPa',\n",
    "                         'Static data Exponent of static strength-': 'Exp_stat_str',\n",
    "                         'Fully reversed push-pull Load frequencyHz': 'Ful_rev_T_C_freq_Hz',\n",
    "                         \"Static data Poisson's ratio-\": 'Pois_rat',\n",
    "                         'Fully reversed bending Fatigue limitMPa': 'Ful_rev_bend_fat_lim_MPa',\n",
    "                         'Rotating bending Fatigue limitMPa': 'Rotat_bend_fat_lim_MPa',\n",
    "                         'Fully reversed bending Number of cycles at fatigue limit-': 'Ful_rev_bend_N_for_fat_lim',\n",
    "                         'Repeated bending Fatigue limitMPa': 'Repeat_bend_fat_lim_MPa',\n",
    "                         'Fully reversed bending Diameter of specimen at active cross-sectionmm': 'Ful_rev_bend_Spec_Diam_mm',\n",
    "                         'Repeated bending Number of cycles at fatigue limit-': 'Repeat_bend_N_for_fat_lim',\n",
    "                         'Fully reversed bending Exponent of S-N curve-': 'Ful_rev_bend_Exp_SN_curv',\n",
    "                         'Static data Shear elasticity modulusMPa': 'Shear_elast_modul_MPa',\n",
    "                         'Carbon content%': 'Carbon_%', 'Silicon content%': 'Silicon_%', \n",
    "                         'Manganese content%': 'Manganese_%', 'Phosphorus content%': 'Phosphorus_%', \n",
    "                         'Sulphur content%': 'Sulphur_%', 'Niobium content%':'Niobium_%',\n",
    "                         'Chromium content%':'Chromium_%', 'Molybdenum content%':'Molybdenum_%', \n",
    "                         'Nickel content%':'Nickel_%', 'Vanadium content%':'Vanadium_%', \n",
    "                         'Wolfram content%':'Wolfram_%', 'Titanium content%':'Titanium_%',\n",
    "                         'Copper content%':'Copper_%', 'Aluminium content%':'Aluminium_%'}, inplace=True)\n",
    "\n",
    "# Dropping columns\n",
    "df_test_4.drop(columns={'CommentaryCommentary', 'mater_group'}, inplace=True)\n",
    "df_test_2.drop(columns={'mater_group'}, inplace=True)\n",
    "\n",
    "# Dropping indexes\n",
    "df_test_4.reset_index(drop=True, inplace=True)\n",
    "df_test_2.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3178c65",
   "metadata": {},
   "source": [
    "Bending, rotating bending, and push-pull tests provide slightly different results. It is due to, for instance, stress gradient on the surface in case of bending. One needs to take it into account. Therefore, let's create the mark if it is a bending test or rotating bending. After that, let's combine the results for axial, shear, and tangential stresses and then drop irrelevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "061851bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the mark if it is a bending test\n",
    "df_test_4['Bending'] = 0\n",
    "bend_ind_4 = df_test_4[['PB - harmonic, constant amplitudeA', 'PB - harmonic, constant amplitudeM', \n",
    "                        'PB - harmonic, constant amplitudeF', 'PB - harmonic, constant amplitudePS']].dropna(how='all').index\n",
    "df_test_4.loc[bend_ind_4,'Bending'] = 1\n",
    "\n",
    "df_test_2['Bending'] = 0\n",
    "bend_ind_2 = df_test_2[['plane bending: constant loadM', 'plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AA',\n",
    "                       'plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AM',\n",
    "                       'plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AF',\n",
    "                       'plane bending: harmonic, constant amplitude\\xa0\\xa0Master - APS']].dropna(how='all').index\n",
    "df_test_2.loc[bend_ind_2,'Bending'] = 1\n",
    "\n",
    "df_test_2['Rot_Bending'] = 0\n",
    "rot_bend_ind_2 = df_test_2[['rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AA',\n",
    "                           'rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AM',\n",
    "                           'rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AF',\n",
    "                           'rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - APS']].dropna(how='all').index\n",
    "df_test_2.loc[rot_bend_ind_2,'Rot_Bending'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f93f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining axial stress data\n",
    "df_test_2['S_m_MPa'] = df_test_2['tension-compression: constant loadM'].fillna(0).astype(float) \\\n",
    "                + df_test_2['tension-compression: harmonic, constant amplitude\\xa0\\xa0Master - AM'].fillna(0).astype(float) \\\n",
    "                + df_test_2['no load: harmonic, constant amplitude\\xa0\\xa0Master - AM'].fillna(0).astype(float) \\\n",
    "                + df_test_2['plane bending: constant loadM'].fillna(0).astype(float) \\\n",
    "                + df_test_2['plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AM'].fillna(0).astype(float) \\\n",
    "                + df_test_2['rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AM'].fillna(0).astype(float)\n",
    "\n",
    "df_test_2['S_a_MPa'] = df_test_2['no load: harmonic, constant amplitude\\xa0\\xa0Master - AA'].fillna(0).astype(float) \\\n",
    "                + df_test_2['tension-compression: harmonic, constant amplitude\\xa0\\xa0Master - AA'].fillna(0).astype(float) \\\n",
    "                + df_test_2['plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AA'].fillna(0).astype(float) \\\n",
    "                + df_test_2['rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AA'].fillna(0).astype(float) \n",
    "\n",
    "df_test_2['Freq_S_Hz'] = df_test_2['no load: harmonic, constant amplitude\\xa0\\xa0Master - AF'].fillna(0).astype(float) \\\n",
    "                + df_test_2['tension-compression: harmonic, constant amplitude\\xa0\\xa0Master - AF'].fillna(0).astype(float) \\\n",
    "                + df_test_2['plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AF'].fillna(0).astype(float) \\\n",
    "                + df_test_2['rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AF'].fillna(0).astype(float) \n",
    "\n",
    "df_test_2['PS_S_deg'] = df_test_2['no load: harmonic, constant amplitude\\xa0\\xa0Master - APS'].fillna(0).astype(float) \\\n",
    "                + df_test_2['tension-compression: harmonic, constant amplitude\\xa0\\xa0Master - APS'].fillna(0).astype(float) \\\n",
    "                + df_test_2['plane bending: harmonic, constant amplitude\\xa0\\xa0Master - APS'].fillna(0).astype(float) \\\n",
    "                + df_test_2['rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - APS'].fillna(0).astype(float)\n",
    "\n",
    "# Combining shear stress data\n",
    "df_test_2['t_m_MPa'] = df_test_2['torsion: harmonic, constant amplitude\\xa0\\xa0Master - AM'].fillna(0).astype(float) \\\n",
    "                + df_test_2['torsion: harmonic, constant amplitudeM'].fillna(0).astype(float) \\\n",
    "                + df_test_2['torsion: constant loadM'].fillna(0).astype(float)\n",
    "\n",
    "df_test_2['t_a_MPa'] = df_test_2['torsion: harmonic, constant amplitude\\xa0\\xa0Master - AA'].fillna(0).astype(float) \\\n",
    "                + df_test_2['torsion: harmonic, constant amplitudeA'].fillna(0).astype(float)\n",
    "\n",
    "df_test_2['Freq_t_Hz'] = df_test_2['torsion: harmonic, constant amplitude\\xa0\\xa0Master - AF'].fillna(0).astype(float) \\\n",
    "                + df_test_2['torsion: harmonic, constant amplitudeF'].fillna(0).astype(float)\n",
    "\n",
    "df_test_2['PS_t_deg'] = df_test_2['torsion: harmonic, constant amplitude\\xa0\\xa0Master - APS'].fillna(0).astype(float) \\\n",
    "                + df_test_2['torsion: harmonic, constant amplitudePS'].fillna(0).astype(float)\n",
    "\n",
    "# Combining tangential stress data\n",
    "df_test_2['tan_m(pres)_MPa)'] = df_test_2['tangential stress (pressurizing): constant loadM'].fillna(0).astype(float) \\\n",
    "    + df_test_2['tangential stress (pressurizing): harmonic, constant amplitude\\xa0\\xa0Master - AM'].fillna(0).astype(float) \\\n",
    "    + df_test_2['tangential stress (pressurizing): harmonic, constant amplitudeM'].fillna(0).astype(float)\n",
    "\n",
    "df_test_2['tan_a(pres)_MPa)'] = df_test_2['tangential stress (pressurizing): harmonic, constant amplitudeA'].fillna(0).astype(float) \\\n",
    "    + df_test_2['tangential stress (pressurizing): harmonic, constant amplitude\\xa0\\xa0Master - AA'].fillna(0).astype(float)\n",
    "\n",
    "df_test_2['Freq_tan_Hz'] = df_test_2['tangential stress (pressurizing): harmonic, constant amplitudeF'].fillna(0).astype(float)\\\n",
    "    + df_test_2['tangential stress (pressurizing): harmonic, constant amplitude\\xa0\\xa0Master - AF'].fillna(0).astype(float)\n",
    "\n",
    "df_test_2['PS_tan_deg'] = df_test_2['tangential stress (pressurizing): harmonic, constant amplitudePS'].fillna(0).astype(float)\\\n",
    "    + df_test_2['tangential stress (pressurizing): harmonic, constant amplitude\\xa0\\xa0Master - APS'].fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb57fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "df_test_2.drop(columns={'tension-compression: constant loadM',\n",
    "                        'tension-compression: harmonic, constant amplitude\\xa0\\xa0Master - AM',\n",
    "                        'no load: harmonic, constant amplitude\\xa0\\xa0Master - AM',\n",
    "                        'plane bending: constant loadM',\n",
    "                        'plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AM',\n",
    "                        'rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AM',\n",
    "                        'no load: harmonic, constant amplitude\\xa0\\xa0Master - AA',\n",
    "                        'tension-compression: harmonic, constant amplitude\\xa0\\xa0Master - AA',\n",
    "                        'plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AA',\n",
    "                        'rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AA',\n",
    "                        'no load: harmonic, constant amplitude\\xa0\\xa0Master - AF',\n",
    "                        'tension-compression: harmonic, constant amplitude\\xa0\\xa0Master - AF',\n",
    "                        'plane bending: harmonic, constant amplitude\\xa0\\xa0Master - AF',\n",
    "                        'rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - AF',\n",
    "                        'no load: harmonic, constant amplitude\\xa0\\xa0Master - APS',\n",
    "                        'tension-compression: harmonic, constant amplitude\\xa0\\xa0Master - APS',\n",
    "                        'plane bending: harmonic, constant amplitude\\xa0\\xa0Master - APS',\n",
    "                        'rotating bending: harmonic, constant amplitude\\xa0\\xa0Master - APS',\n",
    "                        'torsion: harmonic, constant amplitude\\xa0\\xa0Master - AM',\n",
    "                        'torsion: harmonic, constant amplitudeM',\n",
    "                        'torsion: constant loadM',\n",
    "                        'torsion: harmonic, constant amplitude\\xa0\\xa0Master - AA',\n",
    "                        'torsion: harmonic, constant amplitudeA',\n",
    "                        'torsion: harmonic, constant amplitude\\xa0\\xa0Master - AF',\n",
    "                        'torsion: harmonic, constant amplitudeF',\n",
    "                        'torsion: harmonic, constant amplitude\\xa0\\xa0Master - APS',\n",
    "                        'torsion: harmonic, constant amplitudePS',\n",
    "                        'tangential stress (pressurizing): constant loadM',\n",
    "                        'tangential stress (pressurizing): harmonic, constant amplitude\\xa0\\xa0Master - AM',\n",
    "                        'tangential stress (pressurizing): harmonic, constant amplitudeM',\n",
    "                        'tangential stress (pressurizing): harmonic, constant amplitudeA',\n",
    "                        'tangential stress (pressurizing): harmonic, constant amplitude\\xa0\\xa0Master - AA',\n",
    "                        'tangential stress (pressurizing): harmonic, constant amplitudeF',\n",
    "                        'tangential stress (pressurizing): harmonic, constant amplitude\\xa0\\xa0Master - AF',\n",
    "                        'tangential stress (pressurizing): harmonic, constant amplitudePS',\n",
    "                        'tangential stress (pressurizing): harmonic, constant amplitude\\xa0\\xa0Master - APS'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b96ee931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining axial stress data\n",
    "df_test_4['S_m_MPa'] = df_test_4['Ten - constant loadM'].fillna(0).astype(float) \\\n",
    "                    + df_test_4['Ten - harmonic, constant amplitudeM'].fillna(0).astype(float)\\\n",
    "                    + df_test_4['PB - harmonic, constant amplitudeM'].fillna(0).astype(float)\n",
    "\n",
    "df_test_4['S_a_MPa'] = df_test_4['Ten - harmonic, constant amplitudeA'].fillna(0).astype(float)\\\n",
    "                    + df_test_4['PB - harmonic, constant amplitudeA'].fillna(0).astype(float)\n",
    "\n",
    "df_test_4['Freq_S_Hz'] = df_test_4['Ten - harmonic, constant amplitudeF'].fillna(0).astype(float)\\\n",
    "                    + df_test_4['PB - harmonic, constant amplitudeF'].fillna(0).astype(float)\n",
    "\n",
    "df_test_4['PS_S_deg'] = df_test_4['Ten - harmonic, constant amplitudePS'].fillna(0).astype(float)\\\n",
    "                    + df_test_4['PB - harmonic, constant amplitudePS'].fillna(0).astype(float)\n",
    "\n",
    "# Combining shear stress data\n",
    "df_test_4['t_m_MPa'] = df_test_4['To - constant loadM'].fillna(0).astype(float) \\\n",
    "                    + df_test_4['To - harmonic, constant amplitudeM'].fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae3c7f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "df_test_4.drop(columns={'Ten - constant loadM', 'Ten - harmonic, constant amplitudeM', 'PB - harmonic, constant amplitudeM', \n",
    "                        'PB - harmonic, constant amplitudeA', 'Ten - harmonic, constant amplitudeA',\n",
    "                        'Ten - harmonic, constant amplitudeF', 'PB - harmonic, constant amplitudeF',\n",
    "                        'Ten - harmonic, constant amplitudePS', 'PB - harmonic, constant amplitudePS',\n",
    "                        'To - constant loadM', 'To - harmonic, constant amplitudeM'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8d157",
   "metadata": {},
   "source": [
    "The part surface area may affect the fatigue resistance, therefore the next step is to calculate values of the inner and outer surface area as well as the cross-section area of used specimens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15c96e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "# Creating new columns with zeros values\n",
    "df_test_4['CS_Area'] = 0\n",
    "df_test_4['Out_Cov_Area'] = 0\n",
    "df_test_4['Inn_Cov_Area'] = 0\n",
    "\n",
    "# Filling these new columns with calculated values\n",
    "for i in df_test_4.index:\n",
    "    # A solid bar of circular cross-section\n",
    "    if df_test_4['Specimen_type'].loc[i] == 'Solid bar of circular cross-section, unnotched':\n",
    "        # The cross-section area of the specimen\n",
    "        df_test_4['CS_Area'].loc[i] = np.pi/4 * (float(df_test_4['v1 - Diameter [mm]:'].loc[i]))**2\n",
    "        # The outer surface area of the specimen's work part\n",
    "        df_test_4['Out_Cov_Area'].loc[i] = np.pi * float(df_test_4['v1 - Diameter [mm]:'].loc[i]) * \\\n",
    "            float(df_test_4['v2 - Active length [mm]:'].loc[i])\n",
    "        # The inner surface area of the specimen's work part\n",
    "        df_test_4['Inn_Cov_Area'].loc[i] = 0\n",
    "    # Flat solid specimen (GBA)\n",
    "    if (df_test_4['Specimen_type'].loc[i] == 'Flat solid specimen, unnotched' and \n",
    "                df_test_4['pragtic_test_group'].loc[i] == 'GBA'):\n",
    "        # The cross-section area of the specimen\n",
    "        df_test_4['CS_Area'].loc[i] = float(df_test_4['v1 - Width [mm]:'].loc[i]) * \\\n",
    "            float(df_test_4['v6 - Thickness [mm]:'].loc[i])\n",
    "        # The outer surface area of the specimen's work part\n",
    "        df_test_4['Out_Cov_Area'].loc[i] = (float(df_test_4['v1 - Width [mm]:'].loc[i]) + \\\n",
    "            float(df_test_4['v6 - Thickness [mm]:'].loc[i])) * 2 * \\\n",
    "                float(df_test_4['v2 - Active length [mm]:'].loc[i])\n",
    "        # The inner surface area of the specimen's work part\n",
    "        df_test_4['Inn_Cov_Area'].loc[i] = 0\n",
    "    # Flat solid specimen (ST_S)\n",
    "    if (df_test_4['Specimen_type'].loc[i] == 'Flat solid specimen, unnotched' and \n",
    "                df_test_4['pragtic_test_group'].loc[i] == 'ST_S'):\n",
    "        # The cross-section area of the specimen\n",
    "        df_test_4['CS_Area'].loc[i] = float(df_test_4['v1 - Width [mm]:'].loc[i]) * \\\n",
    "            float(df_test_4['v3 - Fillet radius [mm]:'].loc[i])\n",
    "        # The outer surface area of the specimen's work part\n",
    "        df_test_4['Out_Cov_Area'].loc[i] = (float(df_test_4['v1 - Width [mm]:'].loc[i]) + \\\n",
    "            float(df_test_4['v3 - Fillet radius [mm]:'].loc[i])) * 2 * \\\n",
    "                float(df_test_4['v4 - Total length [mm]:'].loc[i])\n",
    "        # The inner surface area of the specimen's work part\n",
    "        df_test_4['Inn_Cov_Area'].loc[i] = 0\n",
    "    # Hollow bar of circular cross-section\n",
    "    if df_test_4['Specimen_type'].loc[i] == 'Hollow bar of circular cross-section, unnotched':\n",
    "        # The cross-section area of the specimen\n",
    "        df_test_4['CS_Area'].loc[i] = np.pi/4 * ((float(df_test_4['v1 - Outer diameter [mm]:'].loc[i]))**2 - \\\n",
    "                                                (float(df_test_4['v2 - Inner diameter [mm]:'].loc[i]))**2)\n",
    "        # The outer surface area of the specimen's work part\n",
    "        df_test_4['Out_Cov_Area'].loc[i] = np.pi * float(df_test_4['v1 - Outer diameter [mm]:'].loc[i]) * \\\n",
    "            float(df_test_4['v3 - Active length [mm]:'].loc[i])\n",
    "        # The inner surface area of the specimen's work part\n",
    "        df_test_4['Inn_Cov_Area'].loc[i] = np.pi * float(df_test_4['v2 - Inner diameter [mm]:'].loc[i]) * \\\n",
    "            float(df_test_4['v3 - Active length [mm]:'].loc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3a77732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is no information about specimen geometry, let's drop the columns\n",
    "df_test_2.drop(columns={'v1 - Diameter [mm]:','v2 - Active length [mm]:','v3 - Fillet radius [mm]:',\n",
    "                        'v5 - Total length [mm]:', 'v4 - Diameter at fixture [mm]:'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998832a8",
   "metadata": {},
   "source": [
    "The last step is to save the resulting DataFrame to a 'CSV' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "id": "108ec6bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_fin = pd.concat([df_4_fin, df_2_fin]).reset_index(drop=True)\n",
    "df_fin.to_csv('fat_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
